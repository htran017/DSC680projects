{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Project 1 - Recommender System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyspark\n",
      "  Downloading pyspark-3.1.1.tar.gz (212.3 MB)\n",
      "Collecting py4j==0.10.9\n",
      "  Downloading py4j-0.10.9-py2.py3-none-any.whl (198 kB)\n",
      "Building wheels for collected packages: pyspark\n",
      "  Building wheel for pyspark (setup.py): started\n",
      "  Building wheel for pyspark (setup.py): finished with status 'done'\n",
      "  Created wheel for pyspark: filename=pyspark-3.1.1-py2.py3-none-any.whl size=212767612 sha256=f51ed584b13babd87abb85e3742f703b15e14a168c283a5c89fd87f92a414700\n",
      "  Stored in directory: c:\\users\\hanhk\\appdata\\local\\pip\\cache\\wheels\\43\\47\\42\\bc413c760cf9d3f7b46ab7cd6590e8c47ebfd19a7386cd4a57\n",
      "Successfully built pyspark\n",
      "Installing collected packages: py4j, pyspark\n",
      "Successfully installed py4j-0.10.9 pyspark-3.1.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a spark session and start it\n",
    "spark = SparkSession.builder.appName('rec').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#build recommendation engine using spark in Alternating Least Squares matrix factorization\n",
    "from pyspark.ml.recommendation import ALS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluate \n",
    "from pyspark.ml.evaluation import RegressionEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data get smaller chunck of data set because the amount of data is too big\n",
    "data = spark.read.csv('rating.csv', inferSchema=True, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------+-------------------+\n",
      "|userId|movieId|rating|          timestamp|\n",
      "+------+-------+------+-------------------+\n",
      "|     1|      2|   3.5|2005-04-02 23:53:47|\n",
      "|     1|     29|   3.5|2005-04-02 23:31:16|\n",
      "|     1|     32|   3.5|2005-04-02 23:33:39|\n",
      "|     1|     47|   3.5|2005-04-02 23:32:07|\n",
      "|     1|     50|   3.5|2005-04-02 23:29:40|\n",
      "|     1|    112|   3.5|2004-09-10 03:09:00|\n",
      "|     1|    151|   4.0|2004-09-10 03:08:54|\n",
      "|     1|    223|   4.0|2005-04-02 23:46:13|\n",
      "|     1|    253|   4.0|2005-04-02 23:35:40|\n",
      "|     1|    260|   4.0|2005-04-02 23:33:46|\n",
      "|     1|    293|   4.0|2005-04-02 23:31:43|\n",
      "|     1|    296|   4.0|2005-04-02 23:32:47|\n",
      "|     1|    318|   4.0|2005-04-02 23:33:18|\n",
      "|     1|    337|   3.5|2004-09-10 03:08:29|\n",
      "|     1|    367|   3.5|2005-04-02 23:53:00|\n",
      "|     1|    541|   4.0|2005-04-02 23:30:03|\n",
      "|     1|    589|   3.5|2005-04-02 23:45:57|\n",
      "|     1|    593|   3.5|2005-04-02 23:31:01|\n",
      "|     1|    653|   3.0|2004-09-10 03:08:11|\n",
      "|     1|    919|   3.5|2004-09-10 03:07:01|\n",
      "+------+-------+------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+------------------+------------------+-------------------+\n",
      "|summary|           userId|           movieId|            rating|          timestamp|\n",
      "+-------+-----------------+------------------+------------------+-------------------+\n",
      "|  count|         20000263|          20000263|          20000263|           20000263|\n",
      "|   mean|69045.87258292554| 9041.567330339605|3.5255285642993797|               null|\n",
      "| stddev|40038.62665316145|19789.477445413166|1.0519889192942444|               null|\n",
      "|    min|                1|                 1|               0.5|1995-01-09 11:46:44|\n",
      "|    max|           138493|            131262|               5.0|2015-03-31 06:40:02|\n",
      "+-------+-----------------+------------------+------------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
